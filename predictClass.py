# -*- coding: utf-8 -*-
"""
Deep Human Pose Estimation

Project by Walid Benbihi
MSc Individual Project
Imperial College
Created on Mon Jul 17 15:50:43 2017

@author: Walid Benbihi
@mail : w.benbihi(at)gmail.com
@github : https://github.com/wbenbihi/hourglasstensorlfow/

Abstract:
	This python code creates a Stacked Hourglass Model
	(Credits : A.Newell et al.)
	(Paper : https://arxiv.org/abs/1603.06937)

	Code translated from 'anewell' github
	Torch7(LUA) --> TensorFlow(PYTHON)
	(Code : https://github.com/anewell/pose-hg-train)

	Modification are made and explained in the report
	Goal : Achieve Real Time detection (Webcam)
	----- Modifications made to obtain faster results (trade off speed/accuracy)

	This work is free of use, please cite the author if you use it!

"""

import sys
import pdb

sys.path.append('./')

from hourglassModel import HourglassModel
from time import time, clock, sleep
import numpy as np
import tensorflow as tf
import scipy.io
from train import process_config
import cv2
from datagen import DataGenerator


class PredictProcessor():
    """
    PredictProcessor class: Give the tools to open and use a trained model for
    prediction.
    Dependency: OpenCV or PIL (OpenCV prefered)

    Comments:
        Every CAPITAL LETTER methods are to be modified with regard to your needs and dataset
    """

    # -------------------------INITIALIZATION METHODS---------------------------
    def __init__(self, config_dict):
        """ Initializer
        Args:
            config_dict	: config_dict
        """
        self.params = config_dict
        self.HG = HourglassModel(nFeat=self.params['nfeats'], nStack=self.params['nstacks'], nLow=self.params['nlow'],outputDim=self.params['num_joints'],batch_size=self.params['batch_size'], drop_rate=self.params['dropout_rate'],lear_rate=self.params['learning_rate'],decay=self.params['learning_rate_decay'], decay_step=self.params['decay_step'],dataset=None, training=False,w_summary=True, logdir_test=self.params['log_dir_test'],logdir_train=self.params['log_dir_test'],name=self.params['name'], joints=self.params['joint_list'])
        self.graph = tf.Graph()
        #self.src = 0
        #self.cam_res = (480, 640)

    def color_palette(self):
        """ Creates a color palette dictionnary
        Drawing Purposes
        You don't need to modify this function.
        In case you need other colors, add BGR color code to the color list
        and make sure to give it a name in the color_name list
        /!\ Make sure those 2 lists have the same size
        """
        # BGR COLOR CODE
        self.color = [(241, 242, 224), (196, 203, 128), (136, 150, 0), (64, 77, 0),
                      (201, 230, 200), (132, 199, 129), (71, 160, 67), (32, 94, 27),
                      (130, 224, 255), (7, 193, 255), (0, 160, 255), (0, 111, 255),
                      (220, 216, 207), (174, 164, 144), (139, 125, 96), (100, 90, 69),
                      (252, 229, 179), (247, 195, 79), (229, 155, 3), (155, 87, 1),
                      (231, 190, 225), (200, 104, 186), (176, 39, 156), (162, 31, 123),
                      (210, 205, 255), (115, 115, 229), (80, 83, 239), (40, 40, 198)]
        # Color Names
        self.color_name = ['teal01', 'teal02', 'teal03', 'teal04',
                           'green01', 'green02', 'green03', 'green04',
                           'amber01', 'amber02', 'amber03', 'amber04',
                           'bluegrey01', 'bluegrey02', 'bluegrey03', 'bluegrey04',
                           'lightblue01', 'lightblue02', 'lightblue03', 'lightblue04',
                           'purple01', 'purple02', 'purple03', 'purple04',
                           'red01', 'red02', 'red03', 'red04']
        self.color_class = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
        self.palette = {}
        for i, name in enumerate(self.color_name):
            self.palette[name] = self.color[i]

    def LINKS_JOINTS(self):
        """ Defines links to be joined for visualization
        Drawing Purposes
        You may need to modify this function
        """
        self.links = {}
        # Edit Links with your needed skeleton
        LINKS = [(0, 1), (1, 2), (2, 4), (4, 6), (1, 3), (3, 5), (5, 7), (2, 8), (8, 10), (10, 12), (3, 9), (9, 11), (11, 13), (8, 9)]
        #self.LINKS_ACP = [(0, 1), (1, 2), (3, 4), (4, 5), (7, 8), (8, 9), (10, 11), (11, 12)]
        color_id = [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 20, 21, 22, 25]
        #self.color_id_acp = [8, 9, 9, 8, 19, 20, 20, 19]
        # 13 joints version
        # LINKS = [(0,1),(1,2),(2,3),(3,4),(4,5),(6,7),(6,11),(11,12),(12,13),(6,11),(10,9),(9,8)]
        # color_id = [1,2,3,2,1,0,27,26,25,27,26,25]
        # 10 lines version
        # LINKS = [(0,1),(1,2),(3,4),(4,5),(6,8),(8,9),(13,14),(14,15),(12,11),(11,10)]
        for i in range(len(LINKS)):
            self.links[i] = {'link': LINKS[i], 'color': self.palette[self.color_name[color_id[i]]]}

    # ----------------------------TOOLS----------------------------------------
    def col2RGB(self, col):
        """
        Args:
            col 	: (int-tuple) Color code in BGR MODE
        Returns
            out 	: (int-tuple) Color code in RGB MODE
        """
        return col[::-1]

    def givePixel(self, link, joints):
        """ Returns the pixel corresponding to a link
        Args:
            link 	: (int-tuple) Tuple of linked joints
            joints	: (array) Array of joints position shape = outDim x 2
        Returns:
            out		: (tuple) Tuple of joints position
        """
        return (joints[link[0]].astype(np.int), joints[link[1]].astype(np.int))

    # ---------------------------MODEL METHODS---------------------------------
    def model_init(self):
        """ Initialize the Hourglass Model
        """
        t = time()
        with self.graph.as_default():
            self.HG.generate_model()
        print('Graph Generated in ', int(time() - t), ' sec.')

    def load_model(self, load=None):
        """ Load pretrained weights (See README)
        Args:
            load : File to load
        """
        with self.graph.as_default():
            self.HG.restore(load)


    def _create_joint_tensor(self, tensor, name='joint_tensor', debug=False):
        """ TensorFlow Computation of Joint Position
        Args:
            tensor		: Prediction Tensor Shape [nbStack x 64 x 64 x outDim] or [64 x 64 x outDim]
            name		: name of the tensor
        Returns:
            out			: Tensor of joints position

        Comment:
            Genuinely Agreeing this tensor is UGLY. If you don't trust me, look at
            'prediction' node in TensorBoard.
            In my defence, I implement it to compare computation times with numpy.
        """
        with tf.name_scope(name):
            shape = tensor.get_shape().as_list()
            if debug:
                print(shape)
            if len(shape) == 3:
                resh = tf.reshape(tensor[:, :, 0], [-1])
            elif len(shape) == 4:
                resh = tf.reshape(tensor[-1, :, :, 0], [-1])
            if debug:
                print(resh)
            arg = tf.argmax(resh, 0)
            if debug:
                print(arg, arg.get_shape(), arg.get_shape().as_list())
            joints = tf.expand_dims(tf.stack([arg // tf.to_int64(shape[1]), arg % tf.to_int64(shape[1])], axis=-1),axis=0)
            for i in range(1, shape[-1]):
                if len(shape) == 3:
                    resh = tf.reshape(tensor[:, :, i], [-1])
                elif len(shape) == 4:
                    resh = tf.reshape(tensor[-1, :, :, i], [-1])
                arg = tf.argmax(resh, 0)
                j = tf.expand_dims(tf.stack([arg // tf.to_int64(shape[1]), arg % tf.to_int64(shape[1])], axis=-1),axis=0)
                joints = tf.concat([joints, j], axis=0)
            return tf.identity(joints, name='joints')


    def _create_prediction_tensor(self):
        """ Create Tensor for prediction purposes
        """
        with self.graph.as_default():
            with tf.name_scope('prediction'):
                self.HG.pred_sigmoid = tf.nn.sigmoid(self.HG.output[:, self.HG.nStack - 1],
                                                     name='sigmoid_final_prediction')
                self.HG.pred_final = self.HG.output[:, self.HG.nStack - 1]
                self.HG.joint_tensor = self._create_joint_tensor(self.HG.output[0], name='joint_tensor')
                self.HG.joint_tensor_final = self._create_joint_tensor(self.HG.output[0, -1], name='joint_tensor_final')
        print('Prediction Tensors Ready!')

    # ----------------------------PREDICTION METHODS----------------------------
    def predict_coarse(self, img, debug=False, sess=None):
        ''' Given a 256 x 256 image, Returns prediction Tensor
        This prediction method returns a non processed Output
        Values not Bounded
        Args:
            img		: Image -Shape (256 x256 x 3) -Type : float32
            debug	: (bool) True to output prediction time
        Returns:
            out		: Array -Shape (nbStacks x 64 x 64 x outputDim) -Type : float32
        '''
        if debug:
            t = time()
        if img.shape == (256, 256, 3):
            if sess is None:
                out = self.HG.Session.run(self.HG.output, feed_dict={self.HG.img: np.expand_dims(img, axis=0)})
            else:
                out = sess.run(self.HG.output, feed_dict={self.HG.img: np.expand_dims(img, axis=0)})
        else:
            print('Image Size does not match placeholder shape')
            raise Exception
        if debug:
            print('Pred: ', time() - t, ' sec.')
        return out

    def pred(self, img, debug=False, sess=None):
        """ Given a 256 x 256 image, Returns prediction Tensor
        This prediction method returns values in [0,1]
        Use this method for inference
        Args:
            img		: Image -Shape (256 x256 x 3) -Type : float32
            debug	: (bool) True to output prediction time
        Returns:
            out		: Array -Shape (64 x 64 x outputDim) -Type : float32
        """
        if debug:
            t = time()
        if img.shape == (256, 256, 3):
            if sess is None:
                out = self.HG.Session.run(self.HG.pred_sigmoid, feed_dict={self.HG.img: np.expand_dims(img, axis=0)})
            else:
                out = sess.run(self.HG.pred_sigmoid, feed_dict={self.HG.img: np.expand_dims(img, axis=0)})
        else:
            print('Image Size does not match placeholder shape')
            raise Exception
        if debug:
            print('Pred: ', time() - t, ' sec.')
        return out

    def joints_pred(self, img, coord='hm', debug=False, sess=None):
        """ Given an Image, Returns an array with joints position
        Args:
            img		: Image -Shape (256 x 256 x 3) -Type : float32
            coord	: 'hm'/'img' Give pixel coordinates relative to heatMap('hm') or Image('img')
            debug	: (bool) True to output prediction time
        Returns
            out		: Array -Shape(num_joints x 2) -Type : int
        """
        if debug:
            t = time()
            if sess is None:
                j1 = self.HG.Session.run(self.HG.joint_tensor, feed_dict={self.HG.img: img})
            else:
                j1 = sess.run(self.HG.joint_tensor, feed_dict={self.HG.img: img})
            print('JT:', time() - t)
            t = time()
            if sess is None:
                j2 = self.HG.Session.run(self.HG.joint_tensor_final, feed_dict={self.HG.img: img})
            else:
                j2 = sess.run(self.HG.joint_tensor_final, feed_dict={self.HG.img: img})
            print('JTF:', time() - t)
            if coord == 'hm':
                return j1, j2
            elif coord == 'img':
                return j1 * self.params['img_size'] / self.params['hm_size'], j2 * self.params['img_size'] / \
                       self.params['hm_size']
            else:
                print("Error: 'coord' argument different of ['hm','img']")
        else:
            if sess is None:
                j = self.HG.Session.run(self.HG.joint_tensor_final, feed_dict={self.HG.img: img})
            else:
                j = sess.run(self.HG.joint_tensor_final, feed_dict={self.HG.img: img})
            if coord == 'hm':
                return j
            elif coord == 'img':
                return j * self.params['img_size'] / self.params['hm_size']
            else:
                print("Error: 'coord' argument different of ['hm','img']")

    def joints_pred_numpy(self, img, coord='hm', thresh=0.2, sess=None):
        """ Create Tensor for joint position prediction
        NON TRAINABLE
        TO CALL AFTER GENERATING GRAPH
        Notes:
            Not more efficient than Numpy, prefer Numpy for such operation!
        """
        if sess is None:
            hm = self.HG.Session.run(self.HG.pred_sigmoid, feed_dict={self.HG.img: img})
        else:
            hm = sess.run(self.HG.pred_sigmoid, feed_dict={self.HG.img: img})
        joints = -1 * np.ones(shape=(self.params['num_joints'], 2))
        for i in range(self.params['num_joints']):
            index = np.unravel_index(hm[0, :, :, i].argmax(), (self.params['hm_size'], self.params['hm_size']))
            if hm[0, index[0], index[1], i] > thresh:
                if coord == 'hm':
                    joints[i] = np.array(index)
                elif coord == 'img':
                    joints[i] = np.array(index) * self.params['img_size'] / self.params['hm_size']
        return joints

    def batch_pred(self, batch, debug=False):
        """ Given a 256 x 256 images, Returns prediction Tensor
        This prediction method returns values in [0,1]
        Use this method for inference
        Args:
            batch	: Batch -Shape (batchSize x 256 x 256 x 3) -Type : float32
            debug	: (bool) True to output prediction time
        Returns:
            out		: Array -Shape (batchSize x 64 x 64 x outputDim) -Type : float32
        """
        if debug:
            t = time()
        if batch[0].shape == (256, 256, 3):
            out = self.HG.Session.run(self.HG.pred_sigmoid, feed_dict={self.HG.img: batch})
        else:
            print('Image Size does not match placeholder shape')
            raise Exception
        if debug:
            print('Pred: ', time() - t, ' sec.')
        return out

    # -------------------------------PLOT FUNCTION------------------------------
    def plt_skeleton(self, img, tocopy=True, debug=False, sess=None):
        """ Given an Image, returns Image with plotted limbs (TF VERSION)
        Args:
            img 	: Source Image shape = (256,256,3)
            tocopy 	: (bool) False to write on source image / True to return a new array
            debug	: (bool) for testing puposes
            sess	: KEEP NONE
        """
        joints = self.joints_pred(np.expand_dims(img, axis=0), coord='img', debug=False, sess=sess)
        if tocopy:
            img = np.copy(img)
        for i in range(len(self.links)):
            position = self.givePixel(self.links[i]['link'], joints)
            cv2.line(img, tuple(position[0])[::-1], tuple(position[1])[::-1], self.links[i]['color'][::-1], thickness=2)
        if tocopy:
            return img

    def plt_skeleton_numpy(self, img, tocopy=True, thresh=0.2, sess=None, joint_plt=True):
        """ Given an Image, returns Image with plotted limbs (NUMPY VERSION)
        Args:
            img			: Source Image shape = (256,256,3)
            tocopy		: (bool) False to write on source image / True to return a new array
            thresh		: Joint Threshold
            sess		: KEEP NONE
            joint_plt	: (bool) True to plot joints (as circles)
        """
        joints = self.joints_pred_numpy(np.expand_dims(img, axis=0), coord='img', thresh=thresh, sess=sess)
        if tocopy:
            img = np.copy(img) * 255
        for i in range(len(self.links)):
            l = self.links[i]['link']
            good_link = True
            for p in l:
                if np.array_equal(joints[p], [-1, -1]):
                    good_link = False
            if good_link:
                position = self.givePixel(self.links[i]['link'], joints)
                cv2.line(img, tuple(position[0])[::-1], tuple(position[1])[::-1], self.links[i]['color'][::-1],
                         thickness=2)
        if joint_plt:
            for p in range(len(joints)):
                if not (np.array_equal(joints[p], [-1, -1])):
                    cv2.circle(img, (int(joints[p, 1]), int(joints[p, 0])), radius=3, color=self.color[p][::-1],
                               thickness=-1)
        if tocopy:
            return img

    def pltSkeleton(self, img, thresh=0.2, pltJ=True, pltL=True, tocopy=True, norm=True):
        """ Plot skeleton on Image (Single Detection)
        Args:
            img			: Input Image ( RGB IMAGE 256x256x3)
            thresh		: Joints Threshold
            pltL		: (bool) Plot Limbs
            tocopy		: (bool) Plot on imput image or return a copy
            norm		: (bool) Normalize input Image (DON'T MODIFY)
        Returns:
            img			: Copy of input image if 'tocopy'
        """
        if tocopy:
            img = np.copy(img)
        if norm:
            img_hg = img / 255
        hg = self.HG.Session.run(self.HG.pred_sigmoid, feed_dict={self.HG.img: np.expand_dims(img_hg, axis=0)})
        j = np.ones(shape=(self.params['num_joints'], 2)) * -1
        for i in range(len(j)):
            idx = np.unravel_index(hg[0, :, :, i].argmax(), (64, 64))
            if hg[0, idx[0], idx[1], i] > thresh:
                j[i] = np.asarray(idx) * 256 / 64
                if pltJ:
                    cv2.circle(img, center=tuple(j[i].astype(np.int))[::-1], radius=5, color=self.color[i][::-1],
                               thickness=-1)
        if pltL:
            for i in range(len(self.links)):
                l = self.links[i]['link']
                good_link = True
                for p in l:
                    if np.array_equal(j[p], [-1, -1]):
                        good_link = False
                if good_link:
                    pos = self.givePixel(l, j)
                    cv2.line(img, tuple(pos[0])[::-1], tuple(pos[1])[::-1], self.links[i]['color'][::-1], thickness=5)
        if tocopy:
            return img

        # -------------------------Benchmark Methods (PCK)-------------------------

    def pcki(self, joint_id, gtJ, prJ, idlh=9, idrs=2):
        """ Compute PCK accuracy on a given joint
        Args:
            joint_id	: Index of the joint considered
            gtJ			: Ground Truth Joint
            prJ			: Predicted Joint
            idlh		: Index of Normalizer (Left Hip on PCK, neck on PCKh)
            idrs		: Index of Normalizer (Right Shoulder on PCK, top head on PCKh)
        Returns:
            (float) NORMALIZED L2 ERROR
        """
        return np.linalg.norm(gtJ[joint_id] - prJ[joint_id][::-1]) / np.linalg.norm(gtJ[idlh] - gtJ[idrs])

    def pck(self, weight, gtJ, prJ, idlh=9, idrs=2):
        """ Compute PCK accuracy for a sample
        Args:
            weight		: Index of the joint considered
            gtJFull	: Ground Truth (sampled on whole image)
            gtJ			: Ground Truth (sampled on reduced image)
            prJ			: Prediction
            boxL		: Box Lenght
            idlh		: Index of Normalizer (Left Hip on PCK, neck on PCKh)
            idrs		: Index of Normalizer (Right Shoulder on PCK, top head on PCKh)
        """
        for i in range(len(weight)):
            if weight[i] == 1:
                self.ratio_pck.append(self.pcki(i, gtJ, prJ, idlh=idlh, idrs=idrs))
                #self.ratio_pck_full.append(self.pcki(i, gtJFull, np.asarray(prJ / 255 * boxL)))
                self.pck_id.append(i)

    def compute_pck(self, datagen, idlh=9, idrs=2, testSet=None):
        """ Compute PCK on dataset
        Args:
            datagen	: (DataGenerator)
            idlh		: Index of Normalizer (Left Hip on PCK, neck on PCKh)
            idrs		: Index of Normalizer (Right Shoulder on PCK, top head on PCKh)
        """
        datagen.pck_ready(idlh=idlh, idrs=idrs, testSet=testSet)
        self.ratio_pck = []
        #self.ratio_pck_full = []
        self.pck_id = []
        self.pck_mean = [0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.]
       # np.array(self.pck_mean)
        samples = len(datagen.pck_samples)
        startT = time()
        for idx, sample in enumerate(datagen.pck_samples):
            percent = (float(idx + 1) / samples) * 100
            num = np.int(20 * percent / 100)
            tToEpoch = int((time() - startT) * (100 - percent) / (percent))
            sys.stdout.write('\r PCK : {0}>'.format("=" * num) + "{0}>".format(" " * (20 - num)) + '||' + str(percent)[
                                                                                                          :4] + '%' + ' -timeToEnd: ' + str(
                tToEpoch) + ' sec.')
            sys.stdout.flush()
            res = datagen.getSample(sample)
            if res != False:
                img, gtJoints, w = res

                prJoints = self.joints_pred_numpy(np.expand_dims(img / 255, axis=0), coord='hm', thresh=0)
                self.pck(w, gtJoints, prJoints, idlh=idlh, idrs=idrs)
                self.pck_mean = [i + j for i,j in zip(self.pck_mean,self.ratio_pck)]
                #self.pck_mean = np.array(self.ratio_pck) + np.array(self.pck_mean)
                self.pltSkeleton(img,thresh=0.2,pltJ=True,pltL=True,tocopy=True,norm=True)
        #self.pck_mean = np.array(self.pck_mean) / len(datagen.pck_samples)
        self.pck_mean = [k / samples for k in self.pck_mean]
        print('pckï¼š','head ',self.pck_mean[0], 'neck ',self.pck_mean[1], 'r_shoulder ',self.pck_mean[2], 'l_shoulder ', self.pck_mean[3],'r_elbow ',self.pck_mean[4], 'l_elbow ',self.pck_mean[5], 'r_wrist ',self.pck_mean[6], 'l_wrist ',self.pck_mean[7], 'r_hip ',self.pck_mean[8], 'l_hip ',self.pck_mean[9], 'r_knee ',self.pck_mean[10], 'l_knee ',self.pck_mean[11], 'r_anckle ',self.pck_mean[12], 'l_anckle ',self.pck_mean[13])
        print('Done in ', int(time() - startT), 'sec.')


# if __name__ == '__main__':
#     t = time()
#     params = process_config('configTiny.cfg')
#     predict = PredictProcessor(params)
#     predict.color_palette()
#     predict.LINKS_JOINTS()
#     predict.model_init()
#     predict.load_model(load='hg_refined_tiny_200')
#     predict._create_prediction_tensor()
#     print('Done: ', time() - t, ' sec.')